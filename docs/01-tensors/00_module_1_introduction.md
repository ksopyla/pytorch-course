# Module 1 â€“ I See Tensors Everywhere ğŸ•¶ï¸

> â€œThere **is** no spoon â€“ there are only tensors.â€ â€” *Neo, probably*

Welcome to the tensor dojo! By cracking open this module you've officially taken the red-pill of deep-learning. From here on out you'll recognise that every pixel, every token, every click-through rate is secretly a multidimensional array begging to be `torch.tensor`-ed.

![pytorch tensors everywhere](../assets/meme_tensors_everywhere.jpg)

In the next few notebooks we'll summon tensors from thin air, slice them like sushi, bend their shapes like a data-wizard and let autograd do the calculus heavy-lifting while we sip â˜•. By the end you'll be able to:

- Create tensors out of numbers, NumPy arrays and pure chaotic randomness.
- Shape-shift them with `view`, `reshape`, `squeeze`, `unsqueeze`, `permute` & friends.
- Crunch serious maths â€“ from element-wise hijinks to the matrix multiplications that power Transformers.
- Charm the GPU, dodge gradient explosions ğŸƒâ€â™‚ï¸ğŸ’¥, and generally look **very** clever in front of your friends.

## Lesson Checklist

1. [Introduction to Tensors](01_introduction_to_tensors.ipynb)
2. [Tensor Manipulation](02_tensor_manipulation.ipynb)
3. [Data Types & Devices](03_data_types_and_devices.ipynb)
4. [Tensor Math Operations](04_tensor_math_operations.ipynb)
5. [Matrix Multiplication](05_matrix_multiplication.ipynb)
6. [Broadcasting](06_broadcasting.ipynb)
7. [Einstein Summation](07_einstein_summation.ipynb)
8. [Advanced Einstein Summation](08_advanced_einstein_summation.ipynb)
9. [Autograd](09_autograd.ipynb)
10. [Gradient Accumulation](10_gradient_accumulation.ipynb)

Feeling brave? The official PyTorch docs are just a click away (<https://pytorch.org/docs/stable/torch.html?utm_source=pytorchcourse.com&utm_medium=pytorch-course&utm_campaign=module-1-intro>). But for now grab your favourite beverage and let's **tensor-ify** the universe! ğŸš€
