{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77c1394",
   "metadata": {},
   "source": [
    "# Matrix Multiplication: Unleashing the Power of Tensors! âš¡\n",
    "\n",
    "> \"Behold! The sacred art of matrix multiplication - where dimensions dance and vectors bend to my will!\" â€” **Professor Victor py Torchenstein**\n",
    "\n",
    "## The Attention Formula (Preview of Things to Come)\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "Where:\n",
    "- $Q$ is the Query matrix\n",
    "- $K$ is the Key matrix  \n",
    "- $V$ is the Value matrix\n",
    "- $d_k$ is the dimension of the key vectors\n",
    "- $\\text{softmax}$ normalizes the attention weights\n",
    "\n",
    "## Basic Matrix Operations\n",
    "\n",
    "Let's start with the fundamentals before we conquer attention mechanisms!\n",
    "\n",
    "### Element-wise vs. Matrix Multiplication\n",
    "\n",
    "Element-wise multiplication: $C_{ij} = A_{ij} \\times B_{ij}$\n",
    "\n",
    "Matrix multiplication: $C_{ij} = \\sum_{k} A_{ik} \\times B_{kj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7c51b9",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
       "\n",
       "Where:\n",
       "- $Q$ is the Query matrix\n",
       "- $K$ is the Key matrix  \n",
       "- $V$ is the Value matrix\n",
       "- $d_k$ is the dimension of the key vectors\n",
       "- $\\text{softmax}$ normalizes the attention weights\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "Where:\n",
    "- $Q$ is the Query matrix\n",
    "- $K$ is the Key matrix  \n",
    "- $V$ is the Value matrix\n",
    "- $d_k$ is the dimension of the key vectors\n",
    "- $\\text{softmax}$ normalizes the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create some matrices for experimentation\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 2)\n",
    "\n",
    "print(\"Matrix A shape:\", A.shape)\n",
    "print(\"Matrix B shape:\", B.shape)\n",
    "\n",
    "# Matrix multiplication\n",
    "C = torch.matmul(A, B)\n",
    "print(\"Result C shape:\", C.shape)\n",
    "print(\"\\nMwahahaha! The matrices have been multiplied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7202ef9",
   "metadata": {},
   "source": [
    "## PyTorch Matrix Multiplication Methods\n",
    "\n",
    "Professor Torchenstein's arsenal includes multiple ways to multiply matrices:\n",
    "\n",
    "1. **`torch.matmul()`** - The general matrix multiplication function\n",
    "2. **`@` operator** - Pythonic matrix multiplication (same as matmul)\n",
    "3. **`torch.mm()`** - For 2D matrices only\n",
    "4. **`torch.bmm()`** - Batch matrix multiplication\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "For matrices $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{n \\times p}$:\n",
    "\n",
    "$$C = AB \\quad \\text{where} \\quad C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj}$$\n",
    "\n",
    "This operation is fundamental to:\n",
    "- Linear transformations\n",
    "- Neural network forward passes  \n",
    "- Attention mechanisms in Transformers\n",
    "- And much more! ðŸ§ âš¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-course-YUNTNAZF-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
