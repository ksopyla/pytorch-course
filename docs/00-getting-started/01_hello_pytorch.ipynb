{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Test your PyTorch setup\n",
    "\n",
    "Welcome to the laboratory, my eager apprentice; our first incantation is a simple one, to ensure your terminal is ready for the raw power we're about to unleash!\n",
    "\n",
    "Start with the most basic example of Python.\n",
    "\n",
    "```python\n",
    "print(\"Hello world\")\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summoning the Beast!\n",
    "\n",
    "Now, we invoke the great PyTorch itself! Let's check its pulse and see if it has found the precious CUDA cores we so desperately need for our electrifying experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behold the Vital Signs!\n",
    "\n",
    "If the stars have aligned and your incantations were correct, you should see a message confirming PyTorch's awakening. But this is merely a surface reading!\n",
    "\n",
    "```bash\n",
    "PyTorch version: 2.7.0+cu126\n",
    "CUDA available: True\n",
    "```\n",
    "\n",
    "Now, let us peer deeper into the machine's soul and examine the very essence of its GPU, CuDNN, and other vital components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "CUDA Device Properties:\n",
      "Device name: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "Device properties: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080 Laptop GPU', major=8, minor=6, total_memory=16383MB, multi_processor_count=48, uuid=4a2f15bc-7268-fcb8-f7b3-9f60002afe35, L2_cache_size=4MB)\n",
      "Current device index: 0\n",
      "Device count: 1\n",
      "\n",
      "CUDA Information:\n",
      "CUDA version: 12.6\n",
      "cuDNN version: 90701\n",
      "cuDNN enabled: True\n",
      "\n",
      "PyTorch Memory Information:\n",
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Display a PyTorch version and GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print CUDA device properties\n",
    "    print(\"\\nCUDA Device Properties:\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device properties: {torch.cuda.get_device_properties(0)}\")\n",
    "    print(f\"Current device index: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # Print CUDA version and capabilities\n",
    "    print(\"\\nCUDA Information:\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"cuDNN enabled: {torch.backends.cudnn.enabled}\")\n",
    "    \n",
    "    # Print PyTorch memory info\n",
    "    print(\"\\nPyTorch Memory Information:\")\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print('GPU not enabled')\n",
    "    print(\"\\nPyTorch Information:\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Backend: {torch.get_default_dtype()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Apparatus is Ready!\n",
    "\n",
    "Mwahahaha! Excellent! You have successfully interrogated the machine and confirmed that the foundational conduits are in place. The GPU's heart beats strong, and the PyTorch beast is straining at its leash, ready for our command.\n",
    "\n",
    "With this knowledge, you are one step closer to bending the very fabric of computation to your will! Our instruments are tuned, the lab is humming with potential. Now, the real work begins..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-course-YUNTNAZF-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
